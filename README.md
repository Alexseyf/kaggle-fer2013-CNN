# FER2013 - Facial Expression Recognition CNN

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este Ã© um projeto de estudo de **Redes Neurais Convolucionais (CNN)** para o reconhecimento de expressÃµes faciais utilizando o dataset **FER2013** (Facial Expression Recognition 2013).

O projeto tem como objetivo:
- Explorar e compreender o dataset FER2013
- Construir e treinar modelos de CNN para classificaÃ§Ã£o de expressÃµes faciais
- Avaliar o desempenho dos modelos
- Estudar tÃ©cnicas de visÃ£o computacional e deep learning

### ExpressÃµes Faciais Classificadas
O modelo Ã© capaz de reconhecer as seguintes 7 categorias de expressÃµes:
1. **Angry** (Raiva)
2. **Disgust** (Nojo)
3. **Fear** (Medo)
4. **Happy** (Felicidade)
5. **Neutral** (Neutro)
6. **Sad** (Tristeza)
7. **Surprise** (Surpresa)

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python** >= 3.12
- **TensorFlow** - Framework para Deep Learning
- **OpenCV** - Processamento de imagens
- **Scikit-learn** - Machine Learning utilities
- **Pandas** - AnÃ¡lise de dados
- **NumPy** - ComputaÃ§Ã£o numÃ©rica
- **Matplotlib & Seaborn** - VisualizaÃ§Ã£o de dados
- **Jupyter Notebook** - Ambiente interativo de desenvolvimento
- **UV** - Gerenciador de pacotes e ambientes virtuais

## ğŸ“¦ PrÃ©-requisitos

- Python 3.12 ou superior
- UV (gerenciador de pacotes) - [InstruÃ§Ãµes de instalaÃ§Ã£o](https://docs.astral.sh/uv/)
- Git (opcional)

## ğŸš€ Guia de InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. Clonar ou acessar o repositÃ³rio

```bash
cd /caminho/para/fer2013
```

### 2. Criar o Ambiente Virtual com UV

Use o comando abaixo para criar um ambiente virtual gerenciado pelo UV:

```bash
uv venv
```

Este comando irÃ¡ criar um ambiente virtual no diretÃ³rio `.venv`.

### 3. Ativar o Ambiente Virtual

No Linux/macOS:
```bash
source .venv/bin/activate
```

No Windows:
```bash
.venv\Scripts\activate
```

VocÃª saberÃ¡ que o ambiente estÃ¡ ativo quando ver `(.venv)` no inÃ­cio da linha do terminal.

### 4. Instalar DependÃªncias com UV

Com o ambiente virtual ativado, instale todas as dependÃªncias do projeto:

```bash
uv sync
```

Este comando irÃ¡:
- Ler as dependÃªncias do arquivo `pyproject.toml`
- Baixar os pacotes necessÃ¡rios
- Instalar todas as bibliotecas especificadas

## ğŸ“¥ ConfiguraÃ§Ã£o do Dataset

### Passo 1: Preparar o DiretÃ³rio de Dados

O dataset serÃ¡ armazenado no diretÃ³rio `data`. Se ainda nÃ£o existir, crie-o:

```bash
mkdir -p data
```

### Passo 2: Baixar o Dataset do Kaggle

1. Acesse o dataset em: https://www.kaggle.com/datasets/msambare/fer2013
2. Clique em "Download"
3. O arquivo `fer2013.zip` serÃ¡ baixado

### Passo 3: Mover o Arquivo ZIP para o DiretÃ³rio Data

ApÃ³s o download, mova o arquivo ZIP para o diretÃ³rio `data`:

```bash
mv ~/Downloads/fer2013.zip data/
```

### Passo 4: Extrair o Arquivo ZIP

Extraia o conteÃºdo do arquivo ZIP:

```bash
cd data
unzip fer2013.zip
cd ..
```

### Passo 5: Estrutura Final do Dataset

ApÃ³s a extraÃ§Ã£o, vocÃª terÃ¡ a seguinte estrutura de diretÃ³rios:

```
data/
â”œâ”€â”€ fer2013.zip (arquivo original)
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ angry/
â”‚   â”œâ”€â”€ disgust/
â”‚   â”œâ”€â”€ fear/
â”‚   â”œâ”€â”€ happy/
â”‚   â”œâ”€â”€ neutral/
â”‚   â”œâ”€â”€ sad/
â”‚   â””â”€â”€ surprise/
â””â”€â”€ test/
    â”œâ”€â”€ angry/
    â”œâ”€â”€ disgust/
    â”œâ”€â”€ fear/
    â”œâ”€â”€ happy/
    â”œâ”€â”€ neutral/
    â”œâ”€â”€ sad/
    â””â”€â”€ surprise/
```

Cada pasta contÃ©m imagens em escala de cinza (.jpg) das expressÃµes faciais correspondentes.

## ğŸ“ Usando o Projeto

### Iniciar o Jupyter Notebook

Com o ambiente virtual ativado, inicie o Jupyter Notebook:

```bash
jupyter notebook
```

Ou para usar JupyterLab (se preferir a interface mais moderna):

```bash
jupyter lab
```

O Jupyter abrirÃ¡ no seu navegador padrÃ£o. Clique em `main.ipynb` para abrir o notebook principal do projeto.

### Estrutura do Notebook

O arquivo `main.ipynb` contÃ©m:
- Carregamento e exploraÃ§Ã£o do dataset
- PrÃ©-processamento de imagens
- ConstruÃ§Ã£o da arquitetura CNN
- Treinamento do modelo
- AvaliaÃ§Ã£o e visualizaÃ§Ã£o dos resultados

## ğŸ’» Comandos RÃ¡pidos

**Reativar o ambiente (em sessÃµes futuras):**
```bash
source .venv/bin/activate
```

**Atualizar dependÃªncias:**
```bash
uv sync
```

**Desativar o ambiente virtual:**
```bash
deactivate
```

**Remover o arquivo ZIP apÃ³s extrair (opcional):**
```bash
rm data/fer2013.zip
```

## ğŸ“Š Estrutura do Projeto

```
fer2013/
â”œâ”€â”€ main.ipynb           # Notebook principal com todo o cÃ³digo
â”œâ”€â”€ pyproject.toml       # DependÃªncias do projeto
â”œâ”€â”€ README.md            # Este arquivo
â”œâ”€â”€ uv.lock              # Lock file do UV (dependÃªncias fixadas)
â””â”€â”€ data/
    â”œâ”€â”€ train/           # Dados de treinamento (28.821 imagens)
    â”œâ”€â”€ test/            # Dados de teste (7.066 imagens)
    â””â”€â”€ fer2013.zip      # Arquivo original (pode ser removido)
```

## ğŸ¯ PrÃ³ximos Passos

1. Configurar o ambiente conforme as instruÃ§Ãµes acima
2. Baixar e extrair o dataset FER2013
3. Abrir `main.ipynb` no Jupyter
4. Executar as cÃ©lulas do notebook sequencialmente
5. Explorar diferentes arquiteturas de CNN
6. Experimentar com tÃ©cnicas de augmentaÃ§Ã£o de dados

## ğŸ“š Recursos Adicionais

- [TensorFlow Documentation](https://www.tensorflow.org/)
- [OpenCV Documentation](https://docs.opencv.org/)
- [Kaggle FER2013 Dataset](https://www.kaggle.com/datasets/msambare/fer2013)
- [Jupyter Documentation](https://jupyter.org/)

## ğŸ“ Notas Importantes

- O treinamento do modelo pode levar algum tempo dependendo da sua mÃ¡quina
- GPU/CUDA pode acelerar significativamente o treinamento
- Certifique-se de ter espaÃ§o em disco suficiente (aproximadamente 1-2 GB para o dataset)
- O dataset contÃ©m imagens de faces em escala de cinza de diferentes etnias, idades e contextos

## ğŸ¤ ContribuiÃ§Ãµes

Este Ã© um projeto de estudo pessoal. ContribuiÃ§Ãµes e sugestÃµes sÃ£o bem-vindas!

## ğŸ“„ LicenÃ§a

Dataset FER2013 foi criado por Pierre-Luc Carrier e Aaron Courville em 2013 e Ã© disponibilizado sob licenÃ§a acadÃªmica.

---

**Ãšltima atualizaÃ§Ã£o:** 25 de outubro de 2025
